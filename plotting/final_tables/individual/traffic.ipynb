{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from seml import get_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_results(\n",
    "    'dp_timeseries_dp_train_standard_eval',\n",
    "    [\n",
    "        'config.seed',\n",
    "        'config.estimator_name',\n",
    "        'config.estimator_kwargs.batch_size',\n",
    "        'config.dp_optimizer_kwargs.max_grad_norm',\n",
    "        'config.dp_optimizer_kwargs.noise_multiplier',\n",
    "        'config.estimator_kwargs.relative_context_length',\n",
    "        'config.dp_accountant_kwargs.budget_epsilon',\n",
    "        'result.metrics_test.mean_wQuantileLoss',\n",
    "        'result.metrics_test.MASE'\n",
    "    ],\n",
    "    to_data_frame=True,\n",
    "    filter_dict={\n",
    "        'config.dataset_kwargs.dataset_name': 'traffic',\n",
    "        'config.estimator_kwargs.trainer_kwargs.max_epochs': 4000,\n",
    "        'config.top_level_mode': 'sampling_without_replacement',\n",
    "        'config.instances_per_sequence': 1,\n",
    "        'config.estimator_kwargs.batch_size': {'$in': [128, 256]},\n",
    "        'config.dp_optimizer_kwargs.max_grad_norm': {'$in': [0.001, 0.0001]},\n",
    "        'config.dp_optimizer_kwargs.noise_multiplier': {'$in': [2.0, 4.0]},\n",
    "        'config.estimator_kwargs.relative_context_length': {'$in': [8]},\n",
    "        'config.dp_accountant_kwargs.budget_delta': 1e-7,\n",
    "        'config.dp_accountant_kwargs.budget_epsilon': {'$in': [0.25, 0.5, 1.0, 2.0, 4.0, 8.0]},\n",
    "        'config.estimator_kwargs.lags_seq': {'$in': [None, [\n",
    "            1, 2, 3, 4, 5, 6, 7, 23, 24, 25, 47, 48, 49, 71, 72, 73,\n",
    "            95, 96, 97, 119, 120, 121, 143, 144, 145, 167, 168, 169]]},\n",
    "        'config.tight_privacy_loss': True\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns[1:]\n",
    "\n",
    "df = df.rename(columns={\n",
    "    c: c.split('.')[-1]\n",
    "    for c in columns\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(df: pd.DataFrame,\n",
    "                 batch_size: int,\n",
    "                 max_grad_norm: float,\n",
    "                 noise_multiplier: float,\n",
    "                 errors: bool = False\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    df = df[\n",
    "        (df['batch_size'] == batch_size)\n",
    "        & (df['max_grad_norm'] == max_grad_norm)\n",
    "        & (df['noise_multiplier'] == noise_multiplier)\n",
    "    ]\n",
    "\n",
    "    print(len(df))\n",
    "\n",
    "    # Average over random seeds\n",
    "    if not errors:\n",
    "        df = df.groupby(\n",
    "            ['max_grad_norm', 'noise_multiplier', 'batch_size', 'estimator_name', 'budget_epsilon']\n",
    "        ).mean().reset_index()\n",
    "    else:\n",
    "        df = df.groupby(\n",
    "            ['max_grad_norm', 'noise_multiplier', 'batch_size', 'estimator_name', 'budget_epsilon']\n",
    "        ).std().reset_index()\n",
    "\n",
    "    df = df.drop(columns=[\n",
    "        '_id',\n",
    "        'seed', 'relative_context_length',\n",
    "        'max_grad_norm', 'noise_multiplier', 'batch_size', '_id'])\n",
    "\n",
    "    df = df.sort_values(by=['estimator_name', 'budget_epsilon'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch size 256, Noise Multiplier 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean = create_table(df, 256, 0.0001, 4.0)\n",
    "df_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std = create_table(df, 256, 0.0001, 4.0, errors=True)\n",
    "df_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "names = ['DLinear', 'DeepAR', 'iTransf.', 'SimpleFF']\n",
    "\n",
    "acc = f'{names[0]} &'\n",
    "\n",
    "for i, (mean, std) in enumerate(zip(df_mean['mean_wQuantileLoss'], df_std['mean_wQuantileLoss'])):\n",
    "\n",
    "    if (i > 0) and ((i % 6)  == 0):\n",
    "        acc += ' ? \\\\\\\\'\n",
    "        print(acc)\n",
    "        acc = f'{names[i // 6]} &'\n",
    "    acc += ' $' + f'{mean:.3f}' + '$ '\n",
    "    acc += '\\\\tiny{$\\\\pm ' + f'{std:.3f}' + '$} &'\n",
    "\n",
    "acc += ' ? \\\\\\\\ '\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timeseries_dp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
